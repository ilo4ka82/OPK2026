"""
–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç ChromaDB.
"""
import logging
from typing import List, Dict
from pathlib import Path
import chromadb
from chromadb.config import Settings

from .document_loader import DocumentChunk
from .embeddings import EmbeddingModel

logger = logging.getLogger(__name__)


class VectorStore:
    """–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ –±–∞–∑–µ ChromaDB"""
    
    def __init__(self, collection_name: str = "ai_knowledge", persist_directory: str = None):
        """
        Args:
            collection_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ ChromaDB
            persist_directory: –ü–∞–ø–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ë–î (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ./data/chroma_db/)
        """
        if persist_directory is None:
            current_dir = Path(__file__).parent
            persist_directory = str(current_dir / "data" / "chroma_db")
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB –≤ {persist_directory}")
        
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        try:
            self.collection = self.client.get_collection(name=collection_name)
            logger.info(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({self.collection.count()} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)")
        except Exception:
            self.collection = self.client.create_collection(name=collection_name)
            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}'")
        
        # –ú–æ–¥–µ–ª—å embeddings
        self.embedder = EmbeddingModel()
    
    def add_documents(self, chunks: List[DocumentChunk], batch_size: int = 100) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (–±–∞—Ç—á–∞–º–∏)
        
        Args:
            chunks: –°–ø–∏—Å–æ–∫ DocumentChunk
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100, ChromaDB –ª–∏–º–∏—Ç ~166)
        """
        if not chunks:
            logger.warning("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")
            return
        
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(chunks)} —á–∞–Ω–∫–æ–≤ –≤ ChromaDB...")
        
        # –°–æ–∑–¥–∞—ë–º embeddings –¥–ª—è –í–°–ï–• —á–∞–Ω–∫–æ–≤ —Å—Ä–∞–∑—É
        texts = [chunk.text for chunk in chunks]
        logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ embeddings –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤...")
        all_embeddings = self.embedder.embed_texts(texts, batch_size=32)
        logger.info(f"‚úÖ Embeddings —Å–æ–∑–¥–∞–Ω—ã")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ ChromaDB –±–∞—Ç—á–∞–º–∏
        total_batches = (len(chunks) + batch_size - 1) // batch_size
        
        for batch_idx in range(0, len(chunks), batch_size):
            batch_chunks = chunks[batch_idx:batch_idx + batch_size]
            batch_embeddings = all_embeddings[batch_idx:batch_idx + batch_size]
            
            batch_texts = []
            batch_metadatas = []
            batch_ids = []
            
            for i, chunk in enumerate(batch_chunks):
                global_idx = batch_idx + i
                
                # –°–æ–∑–¥–∞—ë–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                chunk_id = f"{Path(chunk.source).stem}_chunk_{global_idx}"
                batch_ids.append(chunk_id)
                
                # –¢–µ–∫—Å—Ç
                batch_texts.append(chunk.text)
                
                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    "source": chunk.source,
                    "file_name": Path(chunk.source).name,
                }
                if chunk.page:
                    metadata["page"] = chunk.page
                if chunk.metadata:
                    metadata.update(chunk.metadata)
                
                batch_metadatas.append(metadata)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –±–∞—Ç—á –≤ ChromaDB
            self.collection.add(
                embeddings=batch_embeddings,
                documents=batch_texts,
                metadatas=batch_metadatas,
                ids=batch_ids
            )
            
            current_batch = (batch_idx // batch_size) + 1
            logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –±–∞—Ç—á {current_batch}/{total_batches} ({len(batch_chunks)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)")
        
        logger.info(f"‚úÖ –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(chunks)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ ChromaDB")
    
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        –ò—â–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏: text, source, score, metadata
        """
        logger.info(f"–ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
        
        # –°–æ–∑–¥–∞—ë–º embedding –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedder.embed_text(query)
        
        # –ò—â–µ–º –≤ ChromaDB
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        formatted_results = []
        
        for i in range(len(results["documents"][0])):
            formatted_results.append({
                "text": results["documents"][0][i],
                "source": results["metadatas"][0][i].get("source", "Unknown"),
                "file_name": results["metadatas"][0][i].get("file_name", "Unknown"),
                "page": results["metadatas"][0][i].get("page"),
                "score": 1 - results["distances"][0][i],
                "metadata": results["metadatas"][0][i]
            })
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(formatted_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return formatted_results
    
    def clear_collection(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –≤—Å—é –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        logger.warning(f"–û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{self.collection.name}'")
        self.client.delete_collection(name=self.collection.name)
        self.collection = self.client.create_collection(name=self.collection.name)
        logger.info("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è –æ—á–∏—â–µ–Ω–∞")
    
    def get_count(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        return self.collection.count()


# === –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ===
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    from AI_helper.document_loader import DocumentLoader
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    loader = DocumentLoader()
    documents = loader.load_all_documents(chunk_size=500, chunk_overlap=50)
    
    if not documents:
        print("‚ùå –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏!")
        print("–ü–æ–ª–æ–∂–∏—Ç–µ PDF/DOCX/TXT —Ñ–∞–π–ª—ã –≤ AI_helper/data/ai_knowledge/")
        exit(1)
    
    # –°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    vector_store = VectorStore()
    
    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    # vector_store.clear_collection()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    vector_store.add_documents(documents)
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
    print("\n" + "="*50)
    print("üîç –¢–ï–°–¢–û–í–´–ô –ü–û–ò–°–ö")
    print("="*50)
    
    query = "–ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω—É–∂–Ω—ã –¥–ª—è –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è?"
    results = vector_store.search(query, top_k=3)
    
    for i, result in enumerate(results, 1):
        print(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç {i} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['score']:.2f})")
        print(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {result['file_name']}")
        if result['page']:
            print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞: {result['page']}")
        print(f"–¢–µ–∫—Å—Ç: {result['text'][:200]}...")